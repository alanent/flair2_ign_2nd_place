{"cells":[{"cell_type":"markdown","source":["# FINETUNE SEGFORMER on rgb images (pytorch)\n","\n","---\n","<a target=\"_blank\" href=\"https://colab.research.google.com/drive/1FxU8SOoghUwyI-Eza_gPWllHSXyVok5k\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>\n","\n","https://huggingface.co/docs/transformers/model_doc/segformer"],"metadata":{"id":"FUIYr96QoKoQ"},"id":"FUIYr96QoKoQ"},{"cell_type":"markdown","source":["<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/segformer_architecture.png\"  width=\"600\">\n"],"metadata":{"id":"LDZvoduQLNjI"},"id":"LDZvoduQLNjI"},{"cell_type":"markdown","source":["## Connect do GoogleDrive\n","\n","---\n","\n"],"metadata":{"id":"dC7m1xgHokgv"},"id":"dC7m1xgHokgv"},{"cell_type":"code","execution_count":null,"metadata":{"id":"VlgP4yyUqQWw"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"id":"VlgP4yyUqQWw"},{"cell_type":"markdown","source":["## Install dependencies\n","\n","---\n","\n"],"metadata":{"id":"wdjvW4snowBB"},"id":"wdjvW4snowBB"},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUnQMNXaCiel"},"outputs":[],"source":["%%capture\n","! pip install split-folders\n","! pip install -U accelerate\n","! pip install -U transformers\n","! pip install evaluate\n","! pip install rasterio"],"id":"nUnQMNXaCiel"},{"cell_type":"code","execution_count":null,"metadata":{"id":"A2a23Q-xfPgY"},"outputs":[],"source":["import accelerate\n","import transformers\n","\n","print(transformers.__version__, accelerate.__version__)\n","\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AdamW\n","import torch\n","from torch import nn\n","from sklearn.metrics import accuracy_score\n","from tqdm.notebook import tqdm\n","import os\n","from PIL import Image\n","from transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor\n","import pandas as pd\n","import cv2\n","import numpy as np\n","import albumentations as aug\n","import random\n","import rasterio\n","from pathlib import Path\n","import splitfolders\n","import shutil"],"id":"A2a23Q-xfPgY"},{"cell_type":"markdown","source":["## Check GPU Ressources\n","\n","---\n","\n"],"metadata":{"id":"Y6tWQpu3925Y"},"id":"Y6tWQpu3925Y"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAFPjim0kGYQ"},"outputs":[],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"id":"OAFPjim0kGYQ"},{"cell_type":"markdown","source":["## Unzip training data\n","\n","---\n","\n"],"metadata":{"id":"XL6RZox_-PRX"},"id":"XL6RZox_-PRX"},{"cell_type":"code","source":["!unzip /content/gdrive/MyDrive/FLAIR2/flair_2_dataset/sentinel_mean.zip"],"metadata":{"id":"eREwtm1N5Xye"},"id":"eREwtm1N5Xye","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","!mv /content/content/data /content/data"],"metadata":{"id":"LnZIY7AIVmBC"},"id":"LnZIY7AIVmBC","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ELNa-JwV55io"},"id":"ELNa-JwV55io","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","import sys\n","\n","# Remplacez 'YOUR_PUBLIC_LINK_HERE' par le lien public que vous avez copié.\n","url = 'https://drive.google.com/uc?id=1msf1Kf1sq7qPInDbtrfQg61gwlUnuyYq'\n","\n","import gdown\n","\n","\n","output = 'flair_labels_train.zip'\n","gdown.download(url, output, quiet=False)"],"metadata":{"id":"lJlgg0Wi1JX4"},"id":"lJlgg0Wi1JX4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","!unzip /content/flair_labels_train.zip"],"metadata":{"id":"BGLH1OMcBNgK"},"id":"BGLH1OMcBNgK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import requests\n","# import sys\n","# import gdown\n","\n","# # Remplacez 'YOUR_PUBLIC_LINK_HERE' par le lien public que vous avez copié.\n","# url = 'https://drive.google.com/uc?id=1b3ENX6vsorKY9PgAKPOM5RGoVg0JXFRE'\n","\n","\n","\n","# output = 'flair_aerial_train.zip'\n","# gdown.download(url, output, quiet=False, )"],"metadata":{"id":"B5gTQB14ZaBJ"},"id":"B5gTQB14ZaBJ","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gW8ZmnThPD8n"},"outputs":[],"source":["# %%capture\n","# !unzip /content/flair_aerial_train.zip"],"id":"gW8ZmnThPD8n"},{"cell_type":"code","source":["%%capture\n","!unzip /content/gdrive/MyDrive/FLAIR2/flair_2_dataset/flair_aerial_train.zip"],"metadata":{"id":"JCkLWqVga7i0"},"id":"JCkLWqVga7i0","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Split data for train/val\n","\n","---\n","\n"],"metadata":{"id":"csO0MuKbocXf"},"id":"csO0MuKbocXf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"05ZgYvr1gIJS"},"outputs":[],"source":["! mkdir \"/content/temp\"\n","! mkdir \"/content/data\"\n","! mkdir \"/content/data/masks\"\n","! mkdir \"/content/data/images\"\n","\n","\n","# Chemin du dossier de destination\n","dst_folder = '/content/temp/'\n","\n","# Chemin du dossier source\n","src_folder = '/content/flair_labels_train'\n","for subdir, dirs, files in os.walk(src_folder):\n","    for file in files:\n","        src_file = os.path.join(subdir, file)\n","        dst_file = os.path.join(dst_folder, file)\n","        shutil.move(src_file, dst_folder)\n","\n","# Chemin du dossier source\n","src_folder = '/content/flair_aerial_train'\n","for subdir, dirs, files in os.walk(src_folder):\n","    for file in files:\n","        src_file = os.path.join(subdir, file)\n","        dst_file = os.path.join(dst_folder, file)\n","        shutil.move(src_file, dst_folder)"],"id":"05ZgYvr1gIJS"},{"cell_type":"code","execution_count":null,"metadata":{"id":"zkw1czotBqJB"},"outputs":[],"source":["cd temp"],"id":"zkw1czotBqJB"},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaIKB7Z85Vs5"},"outputs":[],"source":["!mv MSK*.tif /content/data/masks/\n","!mv  IMG*.tif /content/data/images/\n","\n","splitfolders.ratio(\"/content/data/\", seed=1337, ratio=(.999, .001), move=True) # default values"],"id":"NaIKB7Z85Vs5"},{"cell_type":"code","source":["# import shutil\n","# import os\n","\n","# dossier_source = \"/content/temp/content/data/sentinel\"\n","# dossier_destination = \"/content/data/sentinel\"\n","\n","# # Vérifier si le dossier de destination existe, sinon le créer\n","# if not os.path.exists(dossier_destination):\n","#     os.makedirs(dossier_destination)\n","\n","# # Déplacer les fichiers du dossier source vers le dossier de destination\n","# for fichier in os.listdir(dossier_source):\n","#     chemin_source = os.path.join(dossier_source, fichier)\n","#     chemin_destination = os.path.join(dossier_destination, fichier)\n","#     shutil.move(chemin_source, chemin_destination)\n","\n","# print(\"Déplacement terminé.\")\n","\n","\n","\n"],"metadata":{"id":"CErnJcrs4fyh"},"id":"CErnJcrs4fyh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","\n","# dossier = \"/content/data/sentinel\"\n","\n","# # Obtenir la liste des noms de fichiers dans le dossier\n","# noms_fichiers = os.listdir(dossier)\n","\n","# # Compter le nombre de fichiers dans la liste\n","# nombre_fichiers = len(noms_fichiers)\n","\n","# print(f\"Le dossier {dossier} contient {nombre_fichiers} fichiers.\")\n"],"metadata":{"id":"sswQeIyn-k9J"},"id":"sswQeIyn-k9J","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define a class for the image segmentation dataset\n","\n","---\n","\n"],"metadata":{"id":"rnMuiTWco424"},"id":"rnMuiTWco424"},{"cell_type":"code","execution_count":null,"metadata":{"id":"FNMWyoENzw5i"},"outputs":[],"source":["def get_data_paths (path, filter):\n","    for path in Path(path).rglob(filter):\n","        yield path.resolve().as_posix()"],"id":"FNMWyoENzw5i"},{"cell_type":"code","source":["def rgb2gray(rgb):\n","    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"],"metadata":{"id":"dj5Uc6Dm4qMX"},"id":"dj5Uc6Dm4qMX","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie3wHlDxfdM4"},"outputs":[],"source":["import math\n","class ImageSegmentationDataset(Dataset):\n","    \"\"\"Image segmentation dataset.\"\"\"\n","\n","\n","    def __init__(self, root_dir, feature_extractor,transforms):\n","\n","        self.root_dir = root_dir\n","        self.feature_extractor = feature_extractor\n","        print(self.feature_extractor.size)\n","        self.transforms = transforms\n","        self.images = sorted(list(get_data_paths(Path(self.root_dir), 'IMG*.tif')), key=lambda x: int(x.split('_')[-1][:-4]))\n","        self.masks = sorted(list(get_data_paths(Path(self.root_dir), 'MSK*.tif')), key=lambda x: int(x.split('_')[-1][:-4]))\n","        self.sentinel = sorted(list(get_data_paths(Path(self.root_dir), 'SEN*.npy')), key=lambda x: int(x.split('_')[-1][:-4]))\n","        assert len(self.images) == len(self.masks) == len(self.sentinel), \"There must be as many images as there are segmentation maps\"\n","\n","    def read_img(self, raster_file: str) -> np.ndarray:\n","        with rasterio.open(raster_file) as src_img:\n","            rgb = src_img.read([1,2,3]).swapaxes(0, 2).swapaxes(0, 1)\n","            rgb = rgb.astype(np.float32)\n","            return rgb\n","\n","    def read_msk(self, raster_file: str) -> np.ndarray:\n","        with rasterio.open(raster_file) as src_msk:\n","            array = src_msk.read()[0]\n","            array = np.squeeze(array)\n","            return array\n","\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","\n","    def __getitem__(self, idx):\n","\n","        image_file = self.images[idx]\n","        image = self.read_img(raster_file=image_file)\n","\n","\n","        sen = np.load(self.sentinel[idx])\n","        MEAN = np.mean(sen.squeeze(), axis=(1, 2))\n","        STD= np.std(sen.squeeze(), axis=(1, 2))\n","        MEAN = np.array(MEAN)\n","        STD  = np.array(STD)\n","\n","        # Check for NaN values\n","        nan_present = any(math.isnan(x) for x in MEAN)\n","\n","        if nan_present:\n","            MEAN = np.array([0.386759, 0.398155, 0.284823])\n","            STD = np.array([0.087139, 0.070850 , 0.0509254])\n","        else:\n","            pass\n","\n","\n","        test_transform = aug.Compose([   aug.Normalize(mean=MEAN, std=STD)])\n","        image = test_transform(image=image)['image']\n","\n","\n","\n","        mask_file = self.masks[idx]\n","        segmentation_map = self.read_msk(raster_file=mask_file)\n","        segmentation_map[segmentation_map > 12] = 0\n","\n","\n","        encoded_inputs = self.feature_extractor(image, segmentation_map, return_tensors=\"pt\")\n","\n","        for k,v in encoded_inputs.items():\n","            encoded_inputs[k].squeeze_() # remove batch dimension\n","\n","        return encoded_inputs"],"id":"Ie3wHlDxfdM4"},{"cell_type":"markdown","source":["## Data augmentation with albumentation\n","\n","---\n","\n"],"metadata":{"id":"PNAFPKsA_xmf"},"id":"PNAFPKsA_xmf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0WdG6bFOffmP"},"outputs":[],"source":["feature_extractor = SegformerFeatureExtractor(ignore_index=0, reduce_labels=False, do_resize=False, do_rescale=False, do_normalize=False)\n","\n","root_train = '/content/temp/output/train'\n","root_val = '/content/temp/output/val'\n","\n","train_dataset = ImageSegmentationDataset(root_dir=root_train, feature_extractor=feature_extractor,transforms='train')\n","valid_dataset = ImageSegmentationDataset(root_dir=root_val, feature_extractor=feature_extractor,transforms=None)"],"id":"0WdG6bFOffmP"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCxKqT0CfgtQ"},"outputs":[],"source":["print(\"Number of training examples:\", len(train_dataset))\n","print(\"Number of validation examples:\", len(valid_dataset))"],"id":"cCxKqT0CfgtQ"},{"cell_type":"markdown","source":["## Classes metadata\n","\n","---\n","\n"],"metadata":{"id":"re0598WcpDS8"},"id":"re0598WcpDS8"},{"cell_type":"code","source":["def array_to_dict(array):\n","    dictionary = {}\n","    for i, item in enumerate(array):\n","        dictionary[i] = item\n","    return dictionary"],"metadata":{"id":"-j0WDHFfIo5F"},"id":"-j0WDHFfIo5F","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-MvayrKhGFC"},"outputs":[],"source":["classes = ['None','building','pervious surface','impervious surface','bare soil','water','coniferous','deciduous','brushwood','vineyard','herbaceous vegetation','agricultural land','plowed land']\n","id2label = array_to_dict(classes)\n","label2id = {v: k for k, v in id2label.items()}"],"id":"A-MvayrKhGFC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7YN5ArJ3OG-D"},"outputs":[],"source":["num_labels = len(id2label)\n","num_labels"],"id":"7YN5ArJ3OG-D"},{"cell_type":"code","source":[],"metadata":{"id":"VJoCgeJX8tvJ"},"id":"VJoCgeJX8tvJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Plz_xtW1VXRP"},"source":["# Fine-tune a SegFormer model\n","\n","---\n","\n"],"id":"Plz_xtW1VXRP"},{"cell_type":"markdown","metadata":{"id":"3ci_NXUQV02W"},"source":["## Load the model to fine-tune"],"id":"3ci_NXUQV02W"},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6rz8BE1L8Nb","cellView":"form"},"outputs":[],"source":["from transformers import SegformerForSemanticSegmentation\n","\n","pretrained_model_name =  \"nvidia/mit-b5\" #@param {type:\"string\"}\n","model = SegformerForSemanticSegmentation.from_pretrained(\n","    pretrained_model_name,\n","    id2label=id2label,\n","    label2id=label2id,\n","    reshape_last_stage=True,\n","    ignore_mismatched_sizes=True\n",")"],"id":"U6rz8BE1L8Nb"},{"cell_type":"markdown","metadata":{"id":"d7nqNiuZV7du"},"source":["## Set up the Trainer\n","\n","\n","---\n","\n"],"id":"d7nqNiuZV7du"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fZJ2HJcyV8uQ"},"outputs":[],"source":["from transformers import TrainingArguments\n","import torch\n","epochs = 8 #@param {type:\"number\"}\n","lr = 6e-5 #@param {type:\"number\"}\n","batch_size = 4 #@param {type:\"number\"}\n","outputdir = \"/content/segformer_b5_normalize_sentinel2\" #@param {type:\"string\"}\n","\n","\n","from transformers import TrainingArguments\n","training_args = TrainingArguments(\n","    outputdir,\n","    learning_rate=lr,\n","    num_train_epochs=epochs,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=2,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","\n",")"],"id":"fZJ2HJcyV8uQ"},{"cell_type":"markdown","source":["## Metrics for eval\n","\n","---\n","\n"],"metadata":{"id":"CgtnWDZ8qcBj"},"id":"CgtnWDZ8qcBj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"DKOHOKaOL9Ze"},"outputs":[],"source":["import torch\n","from torch import nn\n","import evaluate\n","import multiprocessing\n","\n","import os\n","\n","def check_and_reconnect_drive():\n","    try:\n","        # Check if Google Drive is still connected\n","        os.listdir('/content/gdrive')\n","    except:\n","        # If not, reconnect it\n","        from google.colab import drive\n","        drive.mount('/content/gdrive', force_remount=True)\n","\n","# Then call this function every so often in your main script\n","\n","\n","\n","\n","metric = evaluate.load(\"mean_iou\")\n","\n","def compute_metrics(eval_pred):\n","  with torch.no_grad():\n","    logits, labels = eval_pred\n","    logits_tensor = torch.from_numpy(logits)\n","    # scale the logits to the size of the label\n","    logits_tensor = nn.functional.interpolate(\n","        logits_tensor,\n","        size=labels.shape[-2:],\n","        mode=\"bilinear\",\n","        align_corners=False,\n","    ).argmax(dim=1)\n","\n","    pred_labels = logits_tensor.detach().cpu().numpy()\n","    metrics = metric._compute(\n","            predictions=pred_labels,\n","            references=labels,\n","            num_labels=len(id2label),\n","            ignore_index=False,\n","            # reduce_labels=feature_extractor.reduce_labels,\n","        )\n","\n","    #add per category metrics as individual key-value pairs\n","    per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n","    per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n","\n","    metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n","    metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n","    check_and_reconnect_drive()\n","\n","    return metrics"],"id":"DKOHOKaOL9Ze"},{"cell_type":"markdown","source":["## Training\n","\n","---\n","\n"],"metadata":{"id":"jGdMub0AqjLS"},"id":"jGdMub0AqjLS"},{"cell_type":"code","execution_count":null,"metadata":{"id":"NmyNBmg2Wacv"},"outputs":[],"source":["from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=valid_dataset,\n","    compute_metrics=compute_metrics,\n","\n",")"],"id":"NmyNBmg2Wacv"},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"QPDA98Nbtk4m"},"id":"QPDA98Nbtk4m","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Up9QNqOWtSD"},"outputs":[],"source":["trainer.train()"],"id":"7Up9QNqOWtSD"},{"cell_type":"code","source":["trainer.save_model(\"/content/gdrive/MyDrive/FLAIR2/models/segformer_b5_normalize_sentinel2\")"],"metadata":{"id":"nGZItL-c1aix"},"id":"nGZItL-c1aix","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","private_outputs":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}